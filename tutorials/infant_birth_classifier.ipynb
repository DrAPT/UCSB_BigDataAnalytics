{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: MLlib Classification Modeling\n",
    "\n",
    "### University of California, Santa Barbara  \n",
    "### PSTAT 135/235  \n",
    "### Last Updated: Oct 22, 2018\n",
    "\n",
    "---  \n",
    "\n",
    "### Sources \n",
    "\n",
    "Learning PySpark, Chapter 5\n",
    "\n",
    "### OBJECTIVES\n",
    "- Train a classification model\n",
    "\n",
    "### PREREQUISITES\n",
    "- RDDs\n",
    "- Spark DataFrames\n",
    "- Schemas\n",
    "\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"data preprocessing\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_data = os.path.join('/home/jovyan/UCSB_BigDataAnalytics/data/infant/births_train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='INFANT_ALIVE_AT_REPORT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features for predicting target\n",
    "\n",
    "selected_features = [\n",
    " 'INFANT_ALIVE_AT_REPORT',\n",
    " 'BIRTH_PLACE',\n",
    " 'MOTHER_AGE_YEARS',\n",
    " 'FATHER_COMBINED_AGE',\n",
    " 'CIG_BEFORE',\n",
    " 'CIG_1_TRI',\n",
    " 'CIG_2_TRI',\n",
    " 'CIG_3_TRI',\n",
    " 'MOTHER_HEIGHT_IN',\n",
    " 'MOTHER_PRE_WEIGHT',\n",
    " 'MOTHER_DELIVERY_WEIGHT',\n",
    " 'MOTHER_WEIGHT_GAIN',\n",
    " 'DIABETES_PRE',\n",
    " 'DIABETES_GEST',\n",
    " 'HYP_TENS_PRE',\n",
    " 'HYP_TENS_GEST',\n",
    " 'PREV_BIRTH_PRETERM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n",
    "    ('BIRTH_YEAR', typ.IntegerType()),\n",
    "    ('BIRTH_MONTH', typ.IntegerType()),\n",
    "    ('BIRTH_PLACE', typ.StringType()),\n",
    "    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "    ('MOTHER_RACE_6CODE', typ.StringType()),\n",
    "    ('MOTHER_EDUCATION', typ.StringType()),\n",
    "    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "    ('FATHER_EDUCATION', typ.StringType()),\n",
    "    ('MONTH_PRECARE_RECODE', typ.StringType()),\n",
    "    ('CIG_BEFORE', typ.IntegerType()),\n",
    "    ('CIG_1_TRI', typ.IntegerType()),\n",
    "    ('CIG_2_TRI', typ.IntegerType()),\n",
    "    ('CIG_3_TRI', typ.IntegerType()),\n",
    "    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n",
    "    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "    ('DIABETES_PRE', typ.StringType()),\n",
    "    ('DIABETES_GEST', typ.StringType()),\n",
    "    ('HYP_TENS_PRE', typ.StringType()),\n",
    "    ('HYP_TENS_GEST', typ.StringType()),\n",
    "    ('PREV_BIRTH_PRETERM', typ.StringType()),\n",
    "    ('NO_RISK', typ.StringType()),\n",
    "    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n",
    "    ('LABOR_IND', typ.StringType()),\n",
    "    ('LABOR_AUGM', typ.StringType()),\n",
    "    ('STEROIDS', typ.StringType()),\n",
    "    ('ANTIBIOTICS', typ.StringType()),\n",
    "    ('ANESTHESIA', typ.StringType()),\n",
    "    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n",
    "    ('ATTENDANT_BIRTH', typ.StringType()),\n",
    "    ('APGAR_5', typ.IntegerType()),\n",
    "    ('APGAR_5_RECODE', typ.StringType()),\n",
    "    ('APGAR_10', typ.IntegerType()),\n",
    "    ('APGAR_10_RECODE', typ.StringType()),\n",
    "    ('INFANT_SEX', typ.StringType()),\n",
    "    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n",
    "    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n",
    "    ('INFANT_ASSIST_VENTI', typ.StringType()),\n",
    "    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n",
    "    ('INFANT_NICU_ADMISSION', typ.StringType()),\n",
    "    ('INFANT_SURFACANT', typ.StringType()),\n",
    "    ('INFANT_ANTIBIOTICS', typ.StringType()),\n",
    "    ('INFANT_SEIZURES', typ.StringType()),\n",
    "    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n",
    "    ('INFANT_ANCEPHALY', typ.StringType()),\n",
    "    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n",
    "    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n",
    "    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n",
    "    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n",
    "    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n",
    "    ('INFANT_BREASTFED', typ.StringType())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = typ.StructType([\n",
    " typ.StructField(e[0], e[1], False) for e in labels\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = spark.read.csv(path_to_data,\n",
    " header=True,\n",
    " schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distribution of target variable\n",
    "\n",
    "births.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distribution of a selected feature\n",
    "\n",
    "births.groupBy('INFANT_LIMB_REDUCTION').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow the dataset to selected features and target\n",
    "\n",
    "births_trimmed = births.select(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rows={},columns={}'.format(births_trimmed.count(), len(births_trimmed.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data issue: cigarettes smoked variable values\n",
    "- 0-97 is actual number\n",
    "- 98 is capped value (98+)\n",
    "- 99 is default value for unknown\n",
    "\n",
    "We will recode 99 as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if feature value not 99, then return value, else return 0\n",
    "\n",
    "def correct_cig(feat):\n",
    "    impute_value = 0\n",
    "    return F \\\n",
    "         .when(F.col(feat) != 99, F.col(feat))\\\n",
    "         .otherwise(impute_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the features related to cigarettes smoked\n",
    "\n",
    "births_transformed = births_trimmed \\\n",
    " .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE'))\\\n",
    " .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI'))\\\n",
    " .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI'))\\\n",
    " .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed.describe(['CIG_BEFORE','CIG_1_TRI','CIG_2_TRI','CIG_3_TRI']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some variables are coded as strings Yes/No/Unknown. The will need to be recoded as numerics.\n",
    "Recode dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_dictionary = {\n",
    " 'YNU': {\n",
    " 'Y': 1,\n",
    " 'N': 0,\n",
    " 'U': 0\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup code in dict\n",
    "\n",
    "def recode(col, key):\n",
    " return recode_dictionary[key][col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF to allow recode() to be applied to dataframe\n",
    "\n",
    "rec_integer = F.udf(recode, typ.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate Yes/No/Unknown (YNU) columns\n",
    "\n",
    "cols = [(col.name, col.dataType) for col in births_trimmed.schema]\n",
    "YNU_cols = []\n",
    "for i, s in enumerate(cols):\n",
    "     if s[1] == typ.StringType():\n",
    "         dis = births.select(s[0]) \\\n",
    "         .distinct() \\\n",
    "         .rdd \\\n",
    "         .map(lambda row: row[0]) \\\n",
    "         .collect()\n",
    "     if 'Y' in dis:\n",
    "         YNU_cols.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YNU_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the YNU columns\n",
    "\n",
    "exprs_YNU = [\n",
    " rec_integer(x, F.lit('YNU')).alias(x)\n",
    " if x in YNU_cols\n",
    " else x\n",
    " for x in births_transformed.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_transformed.select(exprs_YNU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.stat as st\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['MOTHER_AGE_YEARS','FATHER_COMBINED_AGE',\n",
    "                'CIG_BEFORE','CIG_1_TRI','CIG_2_TRI','CIG_3_TRI',\n",
    "                 'MOTHER_HEIGHT_IN','MOTHER_PRE_WEIGHT',\n",
    "                 'MOTHER_DELIVERY_WEIGHT','MOTHER_WEIGHT_GAIN'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_rdd = births_transformed \\\n",
    "             .select(numeric_cols) \\\n",
    "             .rdd \\\n",
    "             .map(lambda row: [e for e in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MLlib package for compute stats on columns\n",
    "\n",
    "mllib_stats = st.Statistics.colStats(numeric_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract some stats, zip and print mean, sd\n",
    "\n",
    "for col, m, v in zip(numeric_cols,\n",
    "                     mllib_stats.mean(),\n",
    "                     mllib_stats.variance()):\n",
    " print('{0}: \\t{1:.2f} \\t {2:.2f}'.format(col, m, np.sqrt(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow the list of features for modeling\n",
    "\n",
    "features_to_keep = [\n",
    " 'INFANT_ALIVE_AT_REPORT',\n",
    " 'MOTHER_AGE_YEARS',\n",
    " 'FATHER_COMBINED_AGE',\n",
    " 'CIG_1_TRI',\n",
    " 'MOTHER_HEIGHT_IN',\n",
    " 'MOTHER_PRE_WEIGHT',\n",
    " 'DIABETES_PRE',\n",
    " 'DIABETES_GEST',\n",
    " 'HYP_TENS_PRE',\n",
    " 'HYP_TENS_GEST',\n",
    " 'PREV_BIRTH_PRETERM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_transformed.select([e for e in features_to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib requires an RDD of LabeledPoints\n",
    "\n",
    "LabeledPoint consists of two attributes: *label* and *features*  \n",
    "\n",
    "features can be:\n",
    "\n",
    "- NumPy array,  \n",
    "- list,  \n",
    "- pyspark.mllib.linalg.SparseVector,  \n",
    "- pyspark.mllib.linalg.DenseVector,  \n",
    "- scipy.sparse column matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.regression as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_lp = births_transformed \\\n",
    " .rdd \\\n",
    " .map(lambda row: reg.LabeledPoint(row[0], row[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to split data into training and testing sets (*Data Splitting*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_train, births_test = births_lp.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('count_total={},count_train={},count_test={}'.format(births_transformed.count(),births_train.count(),births_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_Model = LogisticRegressionWithLBFGS.train(births_train, iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from test set, zip labels with predicted labels and cast to float\n",
    "\n",
    "act_pred_test_set = births_test.map(lambda p: (p.label, LR_Model.predict(p.features))) \\\n",
    "                                    .map(lambda row: (row[0], row[1] * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_pred_test_set.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(act_pred_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR: 0.70\n",
      "Area under ROC: 0.69\n"
     ]
    }
   ],
   "source": [
    "print('Area under PR: {0:.2f}'.format(metrics.areaUnderPR))\n",
    "print('Area under ROC: {0:.2f}'.format(metrics.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
