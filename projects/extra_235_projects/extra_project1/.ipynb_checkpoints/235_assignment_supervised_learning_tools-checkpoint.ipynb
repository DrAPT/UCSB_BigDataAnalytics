{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSTAT 235 Extra Assignment 1: Tools for Supervised Learning\n",
    "\n",
    "### University of California, Santa Barbara  \n",
    "### PSTAT 135/235 - Big Data Analytics\n",
    "### Prof Tashman\n",
    "### Last Updated: Jan 31, 2019\n",
    "\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVE: In this assignment, you will code functions to support supervised learning tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"data preprocessing\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in the breast cancer wisconsin data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class, 4 for malignant (positive class)\n",
    "target = 'class'\n",
    "positive_label = 4\n",
    "negative_label = 2\n",
    "\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:  Balancing a DataFrame with Downsampling  \n",
    "i) Write a function to implement downsampling.  \n",
    "\n",
    "INPUTS  \n",
    "* df               - Spark dataframe  \n",
    "* target           - string, target variable  \n",
    "* positive_label   - integer, value of positive label  \n",
    "* negative_label   - integer, value of negative label  \n",
    "\n",
    "OUTPUT  \n",
    "balanced spark dataframe  \n",
    "\n",
    "Downsampling = sample from larger class to match smaller class  \n",
    "\n",
    "ii) Print the target distribution from this balanced dataset, to show the label counts nearly match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE:\n",
    "Sampling won't produce the exact fraction you request. In order to sample efficiently, Spark uses Bernouilli Sampling. \n",
    "Each row is assigned a probability of being included. If you request a 10% sample, each row individually has a 10% chance of being included but this does not guarantee an exact 10% sample   \n",
    "(it should be close, however)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code the function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the target variable distribution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:  Univariate AUC Measurement  \n",
    "\n",
    "In this exercise, you will measure (in a particular sense) the individual predictive power of the following variables:  \n",
    "* clump_thickness\n",
    "* uniformity_cell_size\n",
    "* uniformity_cell_shape\n",
    "* marginal_adhesion\n",
    "* single_epithelial_cell_size\n",
    "\n",
    "Write a function that does the following in this order:  \n",
    "* Split the dataset into training and testing sets (*60% / 40%*, respectively)  \n",
    "* For each variable v:  \n",
    "    * train a logistic regression classifier with intercept, including variable *v* as predictor\n",
    "    * classify each record in the test set  \n",
    "    * measure the area under the ROC curve  \n",
    "* Return a pandas dataframe containing each variable, its model weight (coefficient), and its Univariate AUC, sorted by Univariate AUC in descending order\n",
    "\n",
    "INPUTS  \n",
    "* df, Spark dataframe \n",
    "* target variable as string\n",
    "* training_fraction  \n",
    "* max_iterations  \n",
    "* seed  \n",
    "\n",
    "OUTPUTS  \n",
    "dataframe containing two columns: variable name, AUROC  \n",
    "\n",
    "#### IMPORTANT NOTE:   \n",
    "LabeledPoint requires that positive label = 1, negative label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.mllib.regression as reg\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_fraction = 0.6\n",
    "ITERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow the list of features for modeling\n",
    "\n",
    "vars_to_keep = [\n",
    " 'clump_thickness',\n",
    " 'uniformity_cell_size',\n",
    " 'uniformity_cell_shape',\n",
    " 'marginal_adhesion',\n",
    " 'single_epithelial_cell_size'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map target labels to 0/1\n",
    "brca_f = brca_f.withColumn(target,F.when(brca_f[target] == positive_label, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code the function here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function here, printing results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
