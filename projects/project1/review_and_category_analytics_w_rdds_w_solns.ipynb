{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: Analytics on Glassdoor Reviews and Yelp Category Data\n",
    "\n",
    "### University of California, Santa Barbara  \n",
    "### PSTAT 135/235  \n",
    "### Last Updated: Nov 2, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVE  \n",
    "#### In this assignment, you will perform some basic analytics on review and category data.\n",
    "#### This will entail performing operations on *RDDs*, and using *list comprehensions*.\n",
    "#### Read in the dataset and perform the steps requested below.\n",
    "\n",
    "#### TOTAL POINTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"review_and_category_analytics\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/UCSB_BigDataAnalytics/projects/Project1: Analytics on Glassdoor Reviews and Yelp Category Data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataset  \n",
    "The dataset is saved in the *data* folder. Notice the pathing below, with NO forward slash in front of *data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-20-1a4a71c51f51>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-1a4a71c51f51>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df = sc.textFile(os.path.join(os.getcwd(),'data/reviews_and_categories.csv')\u001b[0m\n\u001b[0m                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "df = sc.textFile(os.path.join(os.getcwd(),'data/reviews_and_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/UCSB_BigDataAnalytics/projects/Project1: Analytics on Glassdoor Reviews and Yelp Category Data'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'reviews_and_categories.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(os.getcwd(),'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o93.partitions.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/data/reviews_and_categories.csv\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c807640ba7bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \"\"\"\n\u001b[1;32m   1344\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0mtotalParts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m         \u001b[0mpartsScanned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mgetNumPartitions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \"\"\"\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o93.partitions.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/data/reviews_and_categories.csv\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index,review,categories'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get non-header records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df.filter(lambda r: r != header) \\\n",
    "        .map(lambda row: [e for e in row.split(',')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the first 2 records (note: exclude the header in all calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0',\n",
       "  '',\n",
       "  '\"[\\'point of interest\\'',\n",
       "  \" 'mexican'\",\n",
       "  \" 'establishment'\",\n",
       "  \" 'food'\",\n",
       "  ' \\'restaurant\\']\"'],\n",
       " ['1', '', '[]']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) get a record count (2 POINTS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store records with non-empty *review_emp_txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_has_review = data.map(lambda r: (r[0],r[1],r[2:])) \\\n",
    "                    .filter(lambda r: r[1] != '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) get a count of records with non-missing reviews (2 POINTS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_has_review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3',\n",
       "  '\"Some franchise owners dock hours. Pros Good discounts on the food. Cons The location where I was working',\n",
       "  [' in North Fresno near Riverpark Mall',\n",
       "   ' was ran by the owner s father who treated the female staff with contempt and derision. Would yell at the staff',\n",
       "   ' in front of the guests',\n",
       "   ' if they didn t exactly follow his formula for making the sandwiches (even when the staff were trying to fulfill the special requests of the guests). He would clock out the closers (with or without their knowledge) before they were done with their tasks',\n",
       "   ' and ask employees to stay an hour or two past the end of their shift',\n",
       "   ' but would not pay them for their time.\"',\n",
       "   '\"[\\'lunch\\'',\n",
       "   \" 'best sandwich'\",\n",
       "   \" 'entertainment'\",\n",
       "   \" 'restaurants'\",\n",
       "   \" 'sub'\",\n",
       "   \" 'arizona'\",\n",
       "   \" 'quick'\",\n",
       "   \" 'social networks'\",\n",
       "   \" 'washington'\",\n",
       "   \" 'catering reno'\",\n",
       "   \" 'establishment'\",\n",
       "   \" 'nevada'\",\n",
       "   \" 'restaurant'\",\n",
       "   \" 'wraps'\",\n",
       "   \" 'qsr'\",\n",
       "   \" 'small business'\",\n",
       "   \" 'meal takeaway'\",\n",
       "   \" 'hospitality'\",\n",
       "   \" 'sandwich'\",\n",
       "   \" 'franchise'\",\n",
       "   \" 'seminars'\",\n",
       "   \" 'deli'\",\n",
       "   \" 'point of interest'\",\n",
       "   \" 'sandwiches'\",\n",
       "   \" 'port'\",\n",
       "   \" 'other'\",\n",
       "   \" 'food'\",\n",
       "   \" 'party trays reno'\",\n",
       "   \" 'service'\",\n",
       "   \" 'entrepeneur'\",\n",
       "   \" 'franchises'\",\n",
       "   \" 'fast food'\",\n",
       "   \" 'grillers'\",\n",
       "   \" 'griller'\",\n",
       "   \" 'salad'\",\n",
       "   \" 'management'\",\n",
       "   \" 'businesses'\",\n",
       "   \" 'self employed'\",\n",
       "   \" 'wrap'\",\n",
       "   \" 'submarine'\",\n",
       "   \" 'delis'\",\n",
       "   \" 'lake tahoe'\",\n",
       "   \" 'boss'\",\n",
       "   \" 'salads'\",\n",
       "   \" 'trade shows'\",\n",
       "   \" 'eating places'\",\n",
       "   \" 'franchising'\",\n",
       "   \" 'reno'\",\n",
       "   \" 'subs'\",\n",
       "   ' \\'phoenix\\']\"']),\n",
       " ('10',\n",
       "  '\"Bushs chicken..more writeups then checks Pros Paid weekly. Nice visor If you have another job they ll work with your schedule Cons This is for belton 1 near the hs. Stuck on counter and drink duty..no tips because customers are too cheap. Carhops are paid way more. I signed up for that but it was only given to veterans. Unrealistic expectations for closing on time. As front of house',\n",
       "  [' you clean the restaurant part',\n",
       "   ' the bathrooms and are still expected to serve customers until 9 00pm..it gets dirty again just silly. Some unrealistic time for getting your duty done and yet u still get wrote up. Why even clean well You might as well work half butt. Most of my writeups were for this. How does 1 person do everything for the front while the carhops get to work more as a team at closing time. Little odd how they run it. I worked at sonic and was only given 1 write up in 8 months and not for cleaning up at the end..just amateur. Here 6 in 2 months. Too many chiefs not enough Indians. I HIGHLY don t recommend working if you re considered cheap labor like I was. Got hired somewhere else knowing I was gonna be fired eventually. There is literally no business in the restaurant only outside. They re looking for the cheapest labor but they are the quickest to be written up. Other restaurants truly value their lowest paid workers. Beware do not work here!\"',\n",
       "   '\"[\\'fried chicken joint\\'',\n",
       "   \" 'american restaurant'\",\n",
       "   \" 'chicken wings'\",\n",
       "   \" 'restaurants'\",\n",
       "   \" 'no outdoor seating'\",\n",
       "   \" 'price'\",\n",
       "   \" 'dining options'\",\n",
       "   \" ' livers'\",\n",
       "   \" 'fried chicken'\",\n",
       "   \" 'gizzards'\",\n",
       "   \" 'fast food restaurant'\",\n",
       "   \" 'fast food'\",\n",
       "   \" 'eating places'\",\n",
       "   \" 'point of interest'\",\n",
       "   \" 'restaurant'\",\n",
       "   \" 'dinner\",\n",
       "   \" lunch & more'\",\n",
       "   \" 'menus'\",\n",
       "   \" ' sweet tea'\",\n",
       "   \" 'establishment'\",\n",
       "   \" 'other'\",\n",
       "   ' \\'food\\']\"']),\n",
       " ('19',\n",
       "  'cashier Pros fun environment and employees were friendly Cons Sometimes they do not have enough employees',\n",
       "  ['\"[\\'credit cards\\'',\n",
       "   \" 'restaurants'\",\n",
       "   \" 'no reservations'\",\n",
       "   \" 'no outdoor seating'\",\n",
       "   \" 'colorado'\",\n",
       "   \" 'menus'\",\n",
       "   \" 'style pizza'\",\n",
       "   \" 'establishment'\",\n",
       "   \" 'price'\",\n",
       "   \" '90 min'\",\n",
       "   \" 'point of interest'\",\n",
       "   \" 'pizza'\",\n",
       "   \" 'other'\",\n",
       "   \" 'food'\",\n",
       "   \" 'dining options'\",\n",
       "   \" 'italian'\",\n",
       "   \" 'napoleon'\",\n",
       "   \" 'pizza place'\",\n",
       "   \" 'delivery'\",\n",
       "   \" 'denver'\",\n",
       "   \" 'dinner\",\n",
       "   \" lunch & more'\",\n",
       "   \" 'eating places'\",\n",
       "   \" 'boulder'\",\n",
       "   \" 'restaurant'\",\n",
       "   ' \\'building\\']\"'])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_has_review.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Return the count of records where review contains the word *awesome*  (2 POINTS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awesome_records = data_has_review.map(lambda r: r[1]) \\\n",
    "                .filter(lambda r: 'awesome' in r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awesome_records.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the records where review contains the word *awesome*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Very awesome. Pros They allow the use of flexible schedule. Cons There are too many hostesses.',\n",
       " 'Not a bad place to work Pros The couple that owned the one I worked at were very big on school and very flexible with my school schedule Being a delivery driver is great because the tips are awesome Cons The owner was kind of crazy I m kind of a health freak and just don t like working with pizza',\n",
       " '\"Cashier Play Attendant Pros The kids are awesome it feels like a family everyone is willing to help awesome food discount Cons needs new equipment like a new espresso machine']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awesome_records.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Lowercase all reviews, then return the count of records where review contains the word *awesome*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awesome_records_lower = data_has_review.map(lambda r: r[1].lower()) \\\n",
    "                .filter(lambda r: 'awesome' in r) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very awesome. pros they allow the use of flexible schedule. cons there are too many hostesses.',\n",
       " 'not a bad place to work pros the couple that owned the one i worked at were very big on school and very flexible with my school schedule being a delivery driver is great because the tips are awesome cons the owner was kind of crazy i m kind of a health freak and just don t like working with pizza',\n",
       " '\"cashier play attendant pros the kids are awesome it feels like a family everyone is willing to help awesome food discount cons needs new equipment like a new espresso machine',\n",
       " 'busboy pros flexible schedule decent tips awesome coworkers 50 employee discount on meals cons physically demanding long hours rude and or impatient customers',\n",
       " '\"awesome place to work pros management is laid back and the work environment is relaxed. everyone that works there is willing to help when you need anything. lots of college kids work there because it is a college town. it s a tremendous job for anyone in boone though. cons there are no cons to working here from my perspective. the job can be high pressure because the restaurant is always busy']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awesome_records_lower.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awesome_records_lower.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Return the top 10 most frequent categories  (4 POINTS)**  \n",
    "\n",
    "Preprocess the categories by:  \n",
    "* stripping characters: &nbsp; [ &nbsp; ] &nbsp;  ' &nbsp;  \"  \n",
    "* trim spaces before and after words  \n",
    "* lowercase\n",
    "\n",
    "NOTE: Be sure to keep terms together, for example 'jet skiing' should not become 'jet', 'skiing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats=data.map(lambda r: r[2:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"[\\'point of interest\\'',\n",
       "  \" 'mexican'\",\n",
       "  \" 'establishment'\",\n",
       "  \" 'food'\",\n",
       "  ' \\'restaurant\\']\"'],\n",
       " ['[]'],\n",
       " ['\"[\\'other\\'', ' \\'food & beverages\\']\"']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats_flat = cats.map(lambda row: [token.replace('[','') \\\n",
    "                                .replace(']','') \\\n",
    "                                .replace(\"'\",'') \\\n",
    "                                .replace('\"','') \\\n",
    "                                .strip() \\\n",
    "                                .lower() for token in row]) \\\n",
    "                                .flatMap(lambda x: x) \\\n",
    "                                .map(lambda x: (x,1)) \\\n",
    "                                .reduceByKey(lambda x,y:x+y) \\\n",
    "                                .map(lambda x:(x[1],x[0])) \\\n",
    "                                .sortByKey(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(718, 'point of interest'),\n",
       " (718, 'establishment'),\n",
       " (717, 'food'),\n",
       " (660, 'restaurant'),\n",
       " (497, 'price'),\n",
       " (483, 'other'),\n",
       " (439, ''),\n",
       " (332, 'credit cards'),\n",
       " (311, 'menus'),\n",
       " (292, 'eating places')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_flat.take(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
