{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Value Pairs\n",
    "\n",
    "### University of California, Santa Barbara  \n",
    "### PSTAT 135/235  \n",
    "### Last Updated: Oct 23, 2018\n",
    "\n",
    "---  \n",
    "\n",
    "### Sources \n",
    "\n",
    "1. Learning Spark\n",
    "\n",
    "### OBJECTIVES\n",
    "1. Learn about properties and methods for pair RDDs\n",
    "\n",
    "\n",
    "### CONCEPTS AND FUNCTIONS\n",
    "- Pair RDDs  \n",
    "- Partition  \n",
    "- reduceByKey(), groupByKey(), combineByKey(), sortByKey()  \n",
    "- mapValues(), flatMapValues()  \n",
    "- keys(), values()  \n",
    "- join(), subtractByKey(), rightOuterJoin(), leftOuterJoin(), cogroup  \n",
    "- countByKey()  \n",
    "- collectAsMap()  \n",
    "- lookup()  \n",
    "- groupWith()  \n",
    "\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAIR RDD BASICS\n",
    "\n",
    "A pair RDD contains key/value pairs (e.g., dictionary in Python)  \n",
    "\n",
    "Useful for merging, aggregating  \n",
    "\n",
    "Calling map() on an RDD will produce a pair RDD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.parallelize(['french fries','chicken burrito'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lines.map(lambda x: (x.split(\" \")[0], x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page 49 contains transformations on pair RDDs  \n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(1,2),(3,4),(3,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the keys\n",
    "rdd.keys().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Transformations**\n",
    "\n",
    "fold()  \n",
    "Similar to reduce, includes “zero value” acting as identity\n",
    "\n",
    "reduceByKey()  \n",
    "Runs several parallel reduce operations, one for each key  \n",
    "Combining is done locally on each machine for each key before computing a global combine for the key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce (sum) by keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.reduceByKey(lambda x,y: x+y) \\\n",
    "   .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revisiting Word Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile('/home/jovyan/work/data/README.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcounts = lines.map(lambda x: x.replace(',',' ') \\\n",
    "                        .replace('.','   ').replace('-',' ').lower()) \\\n",
    "                        .flatMap(lambda x: x.split()) \\\n",
    "                        .map(lambda x: (x, 1)) \\\n",
    "                        .reduceByKey(lambda x,y:x+y) \\\n",
    "                        .map(lambda x:(x[1],x[0])) \\\n",
    "                        .sortByKey(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcounts.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding Frequent Word Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = lines \\\n",
    "            .map(lambda x: x.split()) \\\n",
    "            .flatMap(lambda x: [((x[i],x[i+1]),1) for i in range(0,len(x)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including a reducer and sort by key\n",
    "\n",
    "bigrams = lines \\\n",
    "          .map(lambda x: x.split()) \\\n",
    "          .flatMap(lambda x: [((x[i],x[i+1]),1) for i in range(0,len(x)-1)])\\\n",
    "          .reduceByKey(lambda x,y: x+y) \\\n",
    "          .map(lambda x: (x[1],x[0])) \\\n",
    "          .sortByKey(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partition**  \n",
    "\n",
    "Determines the amount of parallelism when executing on RDDs.  \n",
    "Most operators in this chapter take parameter for partition.  \n",
    "\n",
    "Example: reduceByKey(lambda x, y: x + y, 10)\n",
    "\n",
    "**Join**  \n",
    "join()  is an inner join  \n",
    "leftOuterJoin()  \n",
    "rightOuterJoin()  \n",
    "\n",
    "**Sorting**  \n",
    "Takes param for sort direction.  \n",
    "Can provide comparison function for custom sorting.  \n",
    "Example of converting integers to strings and using string compare function:  \n",
    "rdd.sortByKey(ascending=True, numPartitions=None, keyfunc = lambda x: str(x))  \n",
    "\n",
    "**Actions on Pair RDDs**  \n",
    "All transformations for base RDDs are avail for pair RDDs  \n",
    "Plus some additional like:  \n",
    "countByKey()  \n",
    "collectAsMap()  \n",
    "lookup(key)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(1,2),(3,4),(3,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.lookup(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
