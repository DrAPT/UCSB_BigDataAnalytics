{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ucsb_logo_seal.png\"> \n",
    "\n",
    "## Machine Learning with MLlib - Basic Statistics\n",
    "\n",
    "\n",
    "### PSTAT 135 / 235: Big Data Analytics\n",
    "### University of California, Santa Barbara\n",
    "### Last Updated: Sep 4, 2019\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "Source: Learning Spark  \n",
    "\n",
    "1. Learning Spark  \n",
    "2. Spark Documentation  \n",
    "https://spark.apache.org/docs/latest/mllib-statistics.html\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.random.RandomRDDs\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "-  Introduction to basic statistics capabilities  \n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- Summary statistics\n",
    "- Correlations\n",
    "- Stratified sampling\n",
    "- Hypothesis testing\n",
    "- Random data generation\n",
    "- Kernel density estimation\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Statistics**  \n",
    "\n",
    "`colStats()`  \n",
    "Computes summary of an RDD of vectors. Similar to calling `summary()` on dataframe in R.\n",
    "\n",
    "#### Summary using `colStats()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "rdd = sc.parallelize([Vectors.dense([2, 0, 0, -2]),\n",
    "                      Vectors.dense([4, 5, 0,  3]),\n",
    "                      Vectors.dense([6, 7, 0,  8])])\n",
    "\n",
    "cStats = Statistics.colStats(rdd)\n",
    "cStats.mean()\n",
    "# array([ 4.,  4.,  0.,  3.])\n",
    "\n",
    "cStats.variance()\n",
    "# array([  4.,  13.,   0.,  25.])\n",
    "\n",
    "cStats.count()\n",
    "# 3\n",
    "cStats.numNonzeros()\n",
    "# array([ 3.,  2.,  0.,  3.])\n",
    "\n",
    "cStats.max()\n",
    "# array([ 6.,  7.,  0.,  8.])\n",
    "\n",
    "cStats.min()\n",
    "# array([ 2.,  0.,  0., -2.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation  \n",
    "Currently supports Pearson, Spearman correlation  \n",
    "Takes parameter method. Set to one of ‘pearson’ (default) or ‘spearman’  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "seriesX = sc.parallelize([1.0, 2.0, 3.0, 3.0, 5.0])\n",
    "seriesY = sc.parallelize([11.0, 22.0, 33.0, 33.0, 555.0])\n",
    "\n",
    "Statistics.corr(seriesX,seriesY)\n",
    "# 0.8500286768773007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Sampling\n",
    "\n",
    "For stratified sampling, the keys can be thought of as a label and the value as a specific attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an RDD of any key value pairs\n",
    "data = sc.parallelize([(1, 'a'), (1, 'b'), (2, 'c'), (2, 'd'), (2, 'e'), (3, 'f')])\n",
    "\n",
    "# specify the exact fraction desired from each key as a dictionary\n",
    "fractions = {1: 0.1, 2: 0.6, 3: 0.3}\n",
    "\n",
    "approxSample = data.sampleByKey(False, fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis testing\n",
    "\n",
    "- Pearson’s Independence Test\n",
    "\n",
    "compute the goodness of fit. If a second vector to test against\n",
    "is not supplied as a parameter, the test runs against a uniform distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goodnessOfFitTestResult = Statistics.chiSqTest(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson’s Goodness of Fit (GoF) Test \n",
    "\n",
    "conduct Pearson's independence test on the input contingency matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "independenceTestResult = Statistics.chiSqTest(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kolmogorov-Smirnov Test  \n",
    "\n",
    "`spark.mllib` provides a 1-sample, 2-sided implementation of the Kolmogorov-Smirnov (KS) test for equality of probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Statistics.kolmogorovSmirnovTest(parallelData, \"norm\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random data generation\n",
    "\n",
    "`spark.mllib` supports generating random RDDs with i.i.d. values drawn from a given distribution: \n",
    "- uniform\n",
    "- standard normal\n",
    "- Poisson\n",
    "\n",
    "`RandomRDDs.normalRDD(sc, 1000000L, 10)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel density estimation\n",
    "\n",
    "KDE is a technique useful for visualizing empirical probability distributions without requiring assumptions about the particular distribution that the observed samples are drawn from. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import KernelDensity\n",
    "\n",
    "kd = KernelDensity()\n",
    "kd.setSample(data)\n",
    "kd.setBandwidth(3.0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
