{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ucsb_logo_seal.png\"> \n",
    "\n",
    "## Resilient Distributed Datasets (RDDs)\n",
    "\n",
    "### PSTAT 135 / 235: Big Data Analytics\n",
    "### University of California, Santa Barbara\n",
    "### Last Updated: Sep 4, 2019\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "**Sources:**  \n",
    "Learning Spark, Chapter 3: Programming with RDDs   \n",
    "\n",
    "### OBJECTIVES\n",
    "-  Basics of RDDs including transformations and actions  \n",
    "-  Discuss parallelization concepts  \n",
    "\n",
    "\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- RDD  \n",
    "- Transformation  \n",
    "- Action  \n",
    "- lazy evaluation  \n",
    "- Lineage graph - Graph of dependencies between all involved RDDs  \n",
    "- Set operations  \n",
    "- Pipelining or chaining  \n",
    "- accumulator  \n",
    "- `persist()` and `cache()`  \n",
    "- `parallelize()`  \n",
    "- `collect()` and `take()`  \n",
    "- `map()`, `filter()`, `flatMap()`  \n",
    "- `reduce()`, `fold()`, `aggregate()`  \n",
    "- `count()`, `countByValue()`  \n",
    "- `saveAsTextFile()`, `saveAsSequenceFile()`  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD BASICS\n",
    "\n",
    "An *RDD* is a distributed collection of elements  \n",
    "\n",
    "All work consists of:  \n",
    "- RDD creation  \n",
    "- RDD transformation  \n",
    "- RDD action (e.g., compute a result)  \n",
    "\n",
    "Spark “magically” handles distributing data and code across cluster, parallelization of operations\n",
    "\n",
    "Spark doesn’t actually do any work until it encounters an *action*, for example a `count()`.  \n",
    "It is lazy.  Spark creates a plan or roadmap to optimize performance of the project.\n",
    "\n",
    "When testing/debugging code, it can be helpful to call `count()` to force Spark to evaluate results.\n",
    "\n",
    "A *transformation* creates a new RDD  \n",
    "Actions returns a different data type  \n",
    "\n",
    "RDDs created by:  \n",
    "1. Loading external dataset (`textFile()`, for example)\n",
    "2. Distributing a collection of objects from driver program\n",
    "\n",
    "\n",
    "**Example of Transformation: Filter on text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythonLines = lines.filter(lambda line: \"Python\" in line)\n",
    "py = pythonLines.collect()\n",
    "\n",
    "for i, p in enumerate(py):\n",
    "    print('line: {} text: {}'.format(i,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful Functions on RDDs\n",
    "\n",
    "Store or “persist” an RDD by calling  \n",
    "\n",
    "`RDD.persist()` \n",
    "\n",
    "`cache()` is the same as `persist()` with the default storage level\n",
    "\n",
    "`collect()`  \n",
    "Retrieve entire RDD on driver.  \n",
    "Careful w large RDDs, as the results need to fit in memory on single machine!\n",
    "\n",
    "`take()`  \n",
    "Retrieve small number of elements from RDD (user can specify size).  \n",
    "NOTE: values may NOT be in order\n",
    "\n",
    "`saveAsTextFile()`, `saveAsSequenceFile()`, `…`  \n",
    "Save contents of RDD as a file. Different function call depending on file storage type.\n",
    "\n",
    "\n",
    "#### Basic Transformations \n",
    "\n",
    "`map()`  \n",
    "Applies transform to each element in RDD  \n",
    "\n",
    "`filter()`  \n",
    "Return new RDD with only records meeting condition\n",
    "\n",
    "`parallellize()`  \n",
    "Distribute the data to workers, creating an RDD  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = sc.parallelize([1,2,3,4])\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flatMap()`  \n",
    "Apply map to produce list of elements in a single list (e.g, tokenize a sentence into words)  \n",
    "\n",
    "**Learning Spark** page 36 shows difference between `map()` and `flatMap()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = sc.parallelize(['cat','dog','baby'])\n",
    "list2 = sc.parallelize(['giraffe','baby'])\n",
    "list1.union(list2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this does not filter duplicates  \n",
    "\n",
    "Also notice we can “chain” or “pipeline” commands in sequence  \n",
    "\n",
    "Let’s get the distinct list from the union:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1.union(list2).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: `distinct()` is expensive as it requires shuffling all data over the network  \n",
    "\n",
    "Shuffling: the process of redistributing data across partitions  \n",
    "\n",
    "Page 38 summarizes important basic RDD transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actions\n",
    "\n",
    "`reduce()`  \n",
    "Process elements into a new element of the same type (e.g., add two RDDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = sc.parallelize([1,2,3,4])\n",
    "sum = l1.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('sum: {}'.format(sum))\n",
    "print('l1 type: {}'.format(type(l1)))\n",
    "print('sum type: {}'.format(type(sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fold()`  \n",
    "Similar to `reduce()`, includes “zero value” acting as identity  \n",
    "\n",
    "`aggregate()`  \n",
    "Similar to reduce and fold, uses:  \n",
    "1. initial value \n",
    "2. combining function for each worker or node\n",
    "3. combining function to merge results across workers\n",
    "\n",
    "Page 40 has good code example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`countbyValue()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = sc.parallelize([1,2,3,3,4])\n",
    "cv = nums.countByValue()\n",
    "\n",
    "<class 'collections.defaultdict'>\n",
    "print('cv[1]: {}'.format(cv[1]))\n",
    "print('cv[3]: {}'.format(cv[3]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
