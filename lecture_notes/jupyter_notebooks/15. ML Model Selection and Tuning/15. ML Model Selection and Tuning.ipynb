{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../ucsb_logo_seal.png\"> \n",
    "\n",
    "## ML Model Selection and Tuning\n",
    "\n",
    "### PSTAT 135 / 235: Big Data Analytics\n",
    "### University of California, Santa Barbara\n",
    "### Last Updated: Sep 4, 2019\n",
    "\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "**Sources:**  \n",
    "Learning Spark, Chapter 11: Machine Learning with MLlib  \n",
    "https://spark.apache.org/docs/2.1.1/ml-tuning.html  \n",
    "\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "- Discuss cross validation  \n",
    "- Discuss hyperparameter tuning  \n",
    "- Discuss model evaluation  \n",
    "\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- Data Splitting  \n",
    "- Train/Validation/Test sets  \n",
    "- K-Fold Cross Validation  \n",
    "- CrossValidator  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Model Tuning**\n",
    "\n",
    "Oftentimes, a model will include hyperparameters that need to be tuned for optimal performance.  \n",
    "\n",
    "We have seen many examples, such as the cost parameter in the support vector machine, and the   regularization parameter in L2 regression\n",
    "\n",
    "The optimal value of the hyperparameter cannot be determined in advance, as it depends on the data.  \n",
    "\n",
    "Before a model is trained on data, a plan should be made for *data splitting*.  The purpose of the data splitting step is to accomplish the following:  \n",
    "\n",
    "\n",
    "**1. Model Performance Evaluation**  \n",
    "Set aside a fraction of the data which has not been used for training or tuning.  This test set will be used to evaluate the performance of the model.  If the same data used in training/tuning is also used for evaluation, the results will be too optimistic.  \n",
    "\n",
    "**2. Training and Tuning**  \n",
    "After setting aside the test set, the remaining data will be used for training and tuning.  This train/validation data is often applied in a k-fold cross validation (cv) procedure.  We outline an example cv procedure below.  Typical values for $k$ (the number of folds) are 5 and 10.  \n",
    "\n",
    "The fractions used in the train/validation/test sets will vary depending on factors including the size of the dataset.  \n",
    "\n",
    "Additionally, some users may include more elaborate splitting schemes (e.g, extra validation sets or test sets), depending on the specific problem.  \n",
    "\n",
    "5-Fold Cross Validation with a Separate Test Set  \n",
    "The Training/Validation Sets are 80% of the data; each fold is 16% of the data.  \n",
    "The Test Set is 20% of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation Illustration**  \n",
    "<img src=\"cross_validation_img.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark Implementation of Model Tuning**  \n",
    "\n",
    "First some quick definitions:  \n",
    "\n",
    "\n",
    "- `ParamMaps`: parameters to choose from, aka parameter grid\n",
    "- Estimator:   algorithm or `Pipeline` to tune\n",
    "- Evaluator: metric to measure how well a fitted Model does on held-out test data\n",
    "\n",
    "Tuning can be done on models or pipelines\n",
    "\n",
    "**Important Note:**  \n",
    "Spark validation set = our test set\n",
    "\n",
    "**Methods available for model selection:**  \n",
    "\n",
    "`CrossValidator`\n",
    "\n",
    "`TrainValidationSplit`\n",
    "\n",
    "\n",
    "From https://spark.apache.org/docs/2.1.1/ml-tuning.html\n",
    "\n",
    "Spark `CrossValidator`\n",
    "\n",
    "`CrossValidator` begins by splitting the dataset into a set of folds which are used as separate training and test datasets. E.g., with k=3 folds, `CrossValidator` will generate 3 (training, test) dataset pairs, each of which uses 2/3 of the data for training and 1/3 for testing. To evaluate a particular `ParamMap`, `CrossValidator` computes the average evaluation metric for the 3 Models produced by fitting the `Estimator` on the 3 different (training, test) dataset pairs.\n",
    "After identifying the best `ParamMap`, `CrossValidator` finally re-fits the `Estimator` using the best `ParamMap` and the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`CrossValidator` Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "spark= SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Prepare training documents, which are labeled.\n",
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0),\n",
    "    (4, \"b spark who\", 1.0),\n",
    "    (5, \"g d a y\", 0.0),\n",
    "    (6, \"spark fly\", 1.0),\n",
    "    (7, \"was mapreduce\", 0.0),\n",
    "    (8, \"e spark program\", 1.0),\n",
    "    (9, \"a e c l\", 0.0),\n",
    "    (10, \"spark compile\", 1.0),\n",
    "    (11, \"hadoop software\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])\n",
    "\n",
    "\n",
    "print('training: {}'.format(training))\n",
    "print('type(training): {}'.format(type(training)))\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(paramGrid): {}'.format(len(paramGrid)))\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=2)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "# Prepare test documents, which are unlabeled.\n",
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"mapreduce spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "\n",
    "for row in selected.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**  \n",
    "The call below resulted in a hive error:   \n",
    "`spark.createDataFrame([  `  \n",
    "\n",
    "I made the following change to the shell.py file in   \n",
    "C:\\spark\\spark-2.2.0-bin-hadoop2.7\\python\\pyspark  \n",
    "\n",
    "Commented out enableHiveSupport() from:  \n",
    "\n",
    "        spark = SparkSession.builder\\\n",
    "            .enableHiveSupport()\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`TrainValidationSplit`**  \n",
    "\n",
    "This method only performs one split (unlike the $k$ splits of `CrossValidator`).  \n",
    "Advantage: runtime is faster since the model is trained only once.  \n",
    "Disadvantage: results may not be as reliable out-of-sample of the training dataset isnâ€™t sufficiently large  \n",
    "\n",
    "Method takes parameter `trainRatio`  \n",
    "\n",
    "For example, with `trainRatio` = 0.6, the train/test sets will be 60%/40% of the data, respectively  \n",
    "\n",
    "For an example:  \n",
    "https://spark.apache.org/docs/2.1.1/ml-tuning.html\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
