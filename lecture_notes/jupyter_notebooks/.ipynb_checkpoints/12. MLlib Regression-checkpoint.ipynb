{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ucsb_logo_seal.png\"> \n",
    "\n",
    "## MLlib Regression\n",
    "\n",
    "### PSTAT 135 / 235: Big Data Analytics\n",
    "### University of California, Santa Barbara\n",
    "### Last Updated: Sep 4, 2019\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "**Sources:**  \n",
    "Learning Spark, Chapter 11: Machine Learning with MLlib\n",
    "\n",
    "*Details on regularization equation*  \n",
    "https://spark.apache.org/docs/1.5.2/ml-linear-methods.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression\n",
    "\n",
    "https://spark.apache.org/docs/latest/mllib-ensembles.html#random-forests\n",
    "\n",
    "http://spark.apache.org/docs/latest/ml-classification-regression.html#linear-support-vector-machine\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "- Introduction to major regression models in MLlib\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- Linear regression\n",
    "\n",
    "---\n",
    "\n",
    "**Introduction to Regression**\n",
    "\n",
    "Regression is another common form of supervised learning\n",
    "The response variable in a regression problem is quantitative or continuous  \n",
    "\n",
    "Earlier, we discussed the classification problem where the response variable is discrete\n",
    "\n",
    "Several of the models we discussed for classification also have regression counterparts, including:\n",
    "\n",
    "- Support vector machines  \n",
    "- Tree-based methods like random forests and gradient-boosted trees  \n",
    "\n",
    "To implement the regression counterpart, the same package is loaded but a different method is called.\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "Linear regression is the most fundamental model used in regression.\n",
    "\n",
    "Model assumes a linear relationship between a set of explanatory variables X (aka features, factors, predictors, independent variables) and a scalar response variable y.\n",
    "\n",
    "Most often fit using *ordinary least squares* (*OLS*) approach.  \n",
    "\n",
    "More recently and especially in machine learning, an additional regularization term is added to the loss function. Examples include:\n",
    "\n",
    "- ridge regression ($L^2$-norm penalty)\n",
    "- lasso ($L^1$-norm penalty)\n",
    "\n",
    "**Linear Regression Implementation**  \n",
    "Method `LinearRegressionWithSGD` used to train the model  \n",
    "\n",
    "**Linear Regression Example: load data/train model/predict**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.replace(',', ' ').split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(\"data/mllib/ridge-data/lpsa.data\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Instantiate the model\n",
    "lr= LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "model = lr.fit(parsedData)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "valuesAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "MSE = valuesAndPreds \\\n",
    "    .map(lambda vp: (vp[0] - vp[1])**2) \\\n",
    "    .reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we show function calls to train various models, comparing  classification and regression.  Code is minimal, and the functions and parameters are different.  \n",
    "\n",
    "**Random Forest Implementation**\n",
    "\n",
    "*Classification Model Training*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=1000, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=5, maxBins=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regression Model Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForest.trainRegressor(trainingData, categoricalFeaturesInfo={},\n",
    "                                    numTrees=1000, featureSubsetStrategy=\"auto\",\n",
    "                                    impurity='variance', maxDepth=4, maxBins=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient-Boosted Trees Implementation**\n",
    "\n",
    "<span style=\"color:red\"> Note that Spark GBTs support binary classification, but not multiclass classification. </span> \n",
    "\n",
    "*Classification Model Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostedTrees.trainClassifier(trainingData,\n",
    "                                             categoricalFeaturesInfo={}, numIterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regression Model Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostedTrees.trainRegressor(trainingData,\n",
    "                                            categoricalFeaturesInfo={}, numIterations=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear SVM Implementation**\n",
    "\n",
    "By default, linear SVMs are trained with an $L2$ regularization.  $L1$ regularization is also supported.\n",
    "\n",
    "*Classification Model Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regression Model Training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvm = SVMWithSGD.train(parsedData, iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Measurement**\n",
    "\n",
    "For the classification problem, we discussed measuring performance in terms of misclassification error.\n",
    "For the regression problem, a common metric used for performance measurement is *Mean Squared Error.*\n",
    "\n",
    "**Measuring Mean Squared Error (MSE) for the Regression Problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute squared errors of each point and average\n",
    "\n",
    "testMSE = labelsAndPredictions.map(lambda lp: (lp[0] - lp[1]) * (lp[0] - lp[1])).sum() /\\\n",
    "    float(testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this with the computation of misclassification error for the Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute fraction of points where predicted and actual labels disagree\n",
    "\n",
    "testErr = labelsAndPredictions.filter(\n",
    "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
